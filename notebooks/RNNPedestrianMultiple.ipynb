{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zhangxu0307/time_series_forecasting_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_cols = [\"frame_number\", \"pedestrian_ID\", \"pos_x\", \"pos_z\", \"pos_y\", \"v_x\", \"v_z\", \"v_y\"]\n",
    "url = \"https://raw.githubusercontent.com/AzucenaMV/SocialLSTM/master/eth/eth/obsmat.txt\"\n",
    "df = pd.read_csv(url, delimiter='\\s+', header=None, names = obs_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_number</th>\n",
       "      <th>pedestrian_ID</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_z</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_z</th>\n",
       "      <th>v_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>780.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.456844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.588066</td>\n",
       "      <td>1.671714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>786.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.125530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.658583</td>\n",
       "      <td>1.662877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_number  pedestrian_ID     pos_x  pos_z     pos_y       v_x  v_z  \\\n",
       "0         780.0            1.0  8.456844    0.0  3.588066  1.671714  0.0   \n",
       "1         786.0            1.0  9.125530    0.0  3.658583  1.662877  0.0   \n",
       "\n",
       "        v_y  \n",
       "0  0.176292  \n",
       "1  0.326723  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_frames = 15\n",
    "ids = df.pedestrian_ID.unique()\n",
    "ids_index = [len(df[df.pedestrian_ID == ped]) >= threshold_frames for ped in ids]\n",
    "data_clean = df[df.pedestrian_ID.isin(ids[ids_index])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = 10\n",
    "data_gp_id = data_clean.sort_values(['frame_number']).groupby(['pedestrian_ID'])\n",
    "train_xy = []\n",
    "train_xy_target = []\n",
    "for group_name, data_group in data_gp_id:\n",
    "    L = len(data_group)\n",
    "    for i in range(L-tw):\n",
    "        train_xy.extend(list(zip(data_group.pedestrian_ID[i:i+tw],\n",
    "                                 data_group.pos_x[i:i+tw],\n",
    "                                 data_group.pos_y[i:i+tw])))\n",
    "        train_xy_target.extend(list(zip(data_group.pedestrian_ID[i+tw:i+tw+1],\n",
    "                                 data_group.pos_x[i+tw:i+tw+1],\n",
    "                                 data_group.pos_y[i+tw:i+tw+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = pd.DataFrame(train_xy, columns = ['ID','x','y'])\n",
    "data_targets = pd.DataFrame(train_xy_target, columns = ['ID','x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4499, 10, 2)\n",
      "(4499, 2)\n",
      "(851, 10, 2)\n",
      "(851, 2)\n"
     ]
    }
   ],
   "source": [
    "num_steps_obs = 10\n",
    "num_steps_pred = 1\n",
    "obs = len(data_features)//num_steps_obs\n",
    "data_features_reshape = data_features.drop(columns=['ID']) \\\n",
    "            .values.reshape(obs, num_steps_obs, 2)\n",
    "data_targets_reshape = data_targets.drop(columns=['ID']) \\\n",
    "            .values.reshape(obs, 2)\n",
    "\n",
    "# train \n",
    "X_train = data_features_reshape[1:4500]\n",
    "print(X_train.shape)\n",
    "Y_train = data_targets_reshape[1:4500]\n",
    "print(Y_train.shape)\n",
    "# test\n",
    "X_test = data_features_reshape[4500:]\n",
    "print(X_test.shape)\n",
    "Y_test = data_targets_reshape[4500:]\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast into float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "Y_train = Y_train.astype('float32')\n",
    "Y_test = Y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class Time_Series_Data(Dataset):\n",
    "\n",
    "    def __init__(self, train_x, train_y):\n",
    "        self.X = train_x\n",
    "        self.y = train_y\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        x_t = self.X[item]\n",
    "        y_t = self.y[item]\n",
    "        return x_t, y_t\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNs模型基类，主要是用于指定参数和cell类型\n",
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self, inputDim, hiddenNum, outputDim, layerNum, cell, use_cuda=False):\n",
    "\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.hiddenNum = hiddenNum\n",
    "        self.inputDim = inputDim\n",
    "        self.outputDim = outputDim\n",
    "        self.layerNum = layerNum\n",
    "        self.use_cuda = use_cuda\n",
    "        if cell == \"RNN\":\n",
    "            self.cell = nn.RNN(input_size=self.inputDim, hidden_size=self.hiddenNum,\n",
    "                        num_layers=self.layerNum, dropout=0.0,\n",
    "                         nonlinearity=\"tanh\", batch_first=True,)\n",
    "        if cell == \"LSTM\":\n",
    "            self.cell = nn.LSTM(input_size=self.inputDim, hidden_size=self.hiddenNum,\n",
    "                               num_layers=self.layerNum, dropout=0.0,\n",
    "                               batch_first=True, )\n",
    "        if cell == \"GRU\":\n",
    "            self.cell = nn.GRU(input_size=self.inputDim, hidden_size=self.hiddenNum,\n",
    "                                num_layers=self.layerNum, dropout=0.0,\n",
    "                                 batch_first=True, )\n",
    "        print(self.cell)\n",
    "        #fc - fully connected\n",
    "        self.fc = nn.Linear(self.hiddenNum, self.outputDim) #arg: size of input sample, size of output sample\n",
    "        #the above are setups, these parameters are different from the ones passed in below\n",
    "\n",
    "# 标准RNN模型\n",
    "class RNNModel(BaseModel):\n",
    "\n",
    "    def __init__(self, inputDim, hiddenNum, outputDim, layerNum, cell, use_cuda):\n",
    "\n",
    "        super(RNNModel, self).__init__(inputDim, hiddenNum, outputDim, layerNum, cell, use_cuda)\n",
    "        \n",
    "    #most confused here about the dimensions\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batchSize = x.size(0) #x.dim1 is batchsize 32, x's dim2 should be time series sequence length 24. x(32,24)\n",
    "\n",
    "        h0 = Variable(torch.zeros(self.layerNum * 1, batchSize , self.hiddenNum)) #variable includes backward calc arg\n",
    "        #so it is a 3D - for each layer, each batchsize, each hidden neuron\n",
    "        if self.use_cuda:\n",
    "            h0 = h0.cuda()\n",
    "        rnnOutput, hn = self.cell(x, h0) #?pass in x and a 3D zero tensor? (1,32,64) as h0 input\n",
    "        hn = hn.view(batchSize, self.hiddenNum)  #(32,64)\n",
    "        fcOutput = self.fc(hn) #pass in hidden layer to give linear estimation\n",
    "\n",
    "        return fcOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM模型\n",
    "class LSTMModel(BaseModel):\n",
    "\n",
    "    def __init__(self, inputDim, hiddenNum, outputDim, layerNum, cell, use_cuda):\n",
    "        super(LSTMModel, self).__init__(inputDim, hiddenNum, outputDim, layerNum, cell, use_cuda)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batchSize = x.size(0)\n",
    "        h0 = Variable(torch.zeros(self.layerNum * 1, batchSize, self.hiddenNum))\n",
    "        c0 = Variable(torch.zeros(self.layerNum * 1, batchSize, self.hiddenNum))\n",
    "        if self.use_cuda:\n",
    "            h0 = h0.cuda()\n",
    "            c0 = c0.cuda()\n",
    "        rnnOutput, hn = self.cell(x, (h0, c0))\n",
    "        hn = hn[0].view(batchSize, self.hiddenNum)\n",
    "        fcOutput = self.fc(hn)\n",
    "\n",
    "        return fcOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainX, trainY,  lag, lr, method, hidden_num=64, epoch=20, batchSize=32,\n",
    "           checkPoint=10, use_cuda=False): #hidden_num here is 64, what kind of dimension is this?\n",
    "\n",
    "    lossList = []\n",
    "\n",
    "    # build up data loader\n",
    "    dataset = Time_Series_Data(trainX, trainY)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, sampler=None,\n",
    "                                             batch_sampler=None, num_workers=1)\n",
    "    net = None\n",
    "    if method == \"RNN\": #seems these dim means number of neurons not the dimension of data\n",
    "        net = RNNModel(inputDim=2, hiddenNum=hidden_num, outputDim=2, layerNum=1, cell=\"RNN\", use_cuda=use_cuda)\n",
    "    if method == \"LSTM\":\n",
    "        net = LSTMModel(inputDim=2, hiddenNum=hidden_num, outputDim=2, layerNum=1, cell=\"LSTM\", use_cuda=use_cuda)\n",
    "    if method == \"GRU\":\n",
    "        net = GRUModel(inputDim=2, hiddenNum=hidden_num, outputDim=2, layerNum=1, cell=\"GRU\", use_cuda=use_cuda)\n",
    "    if method == \"ResRNN\":\n",
    "        net = ResRNNModel(inputDim=2, hiddenNum=hidden_num, outputDim=2, resDepth=4, use_cuda=use_cuda)\n",
    "    # if method == \"attention\":\n",
    "    #     net = RNN_Attention(inputDim=1, hiddenNum=hidden_num, outputDim=1, resDepth=4,\n",
    "    #                         seq_len=lag, merge=\"concate\", use_cuda=use_cuda)\n",
    "    if method == \"MLP\":\n",
    "        net = MLPModel(inputDim=lag, hiddenNum=hidden_num, outputDim=1)\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "    net = net.train() #just to let the function know you are training the model.\n",
    "    #So effectively layers like dropout, batchnorm etc. which behave different on the train and test procedures know what is going on and hence can behave accordingly.\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    t1 = time.time()\n",
    "    lossSum = 0\n",
    "\n",
    "    print(\"data loader num:\", len(dataloader))\n",
    "\n",
    "    for i in range(epoch):\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(dataloader):\n",
    "            #set them into variables so that their backpropagation is on\n",
    "            x, y = Variable(x), Variable(y)\n",
    "            if use_cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = net.forward(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            lossSum += loss.item()\n",
    "            if batch_idx % checkPoint == 0 and batch_idx != 0:\n",
    "               print(\"batch: %d , loss is:%f\" % (batch_idx, lossSum / checkPoint))\n",
    "               lossList.append(lossSum / checkPoint)\n",
    "               lossSum = 0\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"%d epoch is finished!\" % (i+1))\n",
    "\n",
    "    t2 = time.time()\n",
    "    print(\"train time:\", t2-t1)\n",
    "    #p.dump(lossList, output, -1)\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(2, 30, batch_first=True)\n",
      "data loader num: 45\n",
      "batch: 10 , loss is:22.211610\n",
      "batch: 20 , loss is:5.198295\n",
      "batch: 30 , loss is:2.411288\n",
      "batch: 40 , loss is:1.567796\n",
      "1 epoch is finished!\n",
      "batch: 10 , loss is:1.272195\n",
      "batch: 20 , loss is:0.501405\n",
      "batch: 30 , loss is:0.285970\n",
      "batch: 40 , loss is:0.250425\n",
      "2 epoch is finished!\n",
      "batch: 10 , loss is:0.238179\n",
      "batch: 20 , loss is:0.125735\n",
      "batch: 30 , loss is:0.098248\n",
      "batch: 40 , loss is:0.118173\n",
      "3 epoch is finished!\n",
      "batch: 10 , loss is:0.125195\n",
      "batch: 20 , loss is:0.074534\n",
      "batch: 30 , loss is:0.058537\n",
      "batch: 40 , loss is:0.054384\n",
      "4 epoch is finished!\n",
      "batch: 10 , loss is:0.075220\n",
      "batch: 20 , loss is:0.047672\n",
      "batch: 30 , loss is:0.039660\n",
      "batch: 40 , loss is:0.035501\n",
      "5 epoch is finished!\n",
      "batch: 10 , loss is:0.054807\n",
      "batch: 20 , loss is:0.035633\n",
      "batch: 30 , loss is:0.032014\n",
      "batch: 40 , loss is:0.034855\n",
      "6 epoch is finished!\n",
      "batch: 10 , loss is:0.044967\n",
      "batch: 20 , loss is:0.030590\n",
      "batch: 30 , loss is:0.028059\n",
      "batch: 40 , loss is:0.024218\n",
      "7 epoch is finished!\n",
      "batch: 10 , loss is:0.040610\n",
      "batch: 20 , loss is:0.024857\n",
      "batch: 30 , loss is:0.024370\n",
      "batch: 40 , loss is:0.024345\n",
      "8 epoch is finished!\n",
      "batch: 10 , loss is:0.035590\n",
      "batch: 20 , loss is:0.023783\n",
      "batch: 30 , loss is:0.022455\n",
      "batch: 40 , loss is:0.024283\n",
      "9 epoch is finished!\n",
      "batch: 10 , loss is:0.033778\n",
      "batch: 20 , loss is:0.023082\n",
      "batch: 30 , loss is:0.025281\n",
      "batch: 40 , loss is:0.025273\n",
      "10 epoch is finished!\n",
      "batch: 10 , loss is:0.034362\n",
      "batch: 20 , loss is:0.021766\n",
      "batch: 30 , loss is:0.019306\n",
      "batch: 40 , loss is:0.021018\n",
      "11 epoch is finished!\n",
      "batch: 10 , loss is:0.027608\n",
      "batch: 20 , loss is:0.021135\n",
      "batch: 30 , loss is:0.019648\n",
      "batch: 40 , loss is:0.021439\n",
      "12 epoch is finished!\n",
      "batch: 10 , loss is:0.032006\n",
      "batch: 20 , loss is:0.017174\n",
      "batch: 30 , loss is:0.016496\n",
      "batch: 40 , loss is:0.018033\n",
      "13 epoch is finished!\n",
      "batch: 10 , loss is:0.026073\n",
      "batch: 20 , loss is:0.021147\n",
      "batch: 30 , loss is:0.017374\n",
      "batch: 40 , loss is:0.018769\n",
      "14 epoch is finished!\n",
      "batch: 10 , loss is:0.027773\n",
      "batch: 20 , loss is:0.019095\n",
      "batch: 30 , loss is:0.017312\n",
      "batch: 40 , loss is:0.019004\n",
      "15 epoch is finished!\n",
      "batch: 10 , loss is:0.032262\n",
      "batch: 20 , loss is:0.022267\n",
      "batch: 30 , loss is:0.022703\n",
      "batch: 40 , loss is:0.019169\n",
      "16 epoch is finished!\n",
      "batch: 10 , loss is:0.023574\n",
      "batch: 20 , loss is:0.016181\n",
      "batch: 30 , loss is:0.016404\n",
      "batch: 40 , loss is:0.019561\n",
      "17 epoch is finished!\n",
      "batch: 10 , loss is:0.032085\n",
      "batch: 20 , loss is:0.015998\n",
      "batch: 30 , loss is:0.014889\n",
      "batch: 40 , loss is:0.016078\n",
      "18 epoch is finished!\n",
      "batch: 10 , loss is:0.025436\n",
      "batch: 20 , loss is:0.015068\n",
      "batch: 30 , loss is:0.015000\n",
      "batch: 40 , loss is:0.017000\n",
      "19 epoch is finished!\n",
      "batch: 10 , loss is:0.027387\n",
      "batch: 20 , loss is:0.020151\n",
      "batch: 30 , loss is:0.014727\n",
      "batch: 40 , loss is:0.015062\n",
      "20 epoch is finished!\n",
      "train time: 8.276263952255249\n"
     ]
    }
   ],
   "source": [
    "# trainX needs to be 3D array (non tensor), float32\n",
    "trained_RNN = train(X_train, \n",
    "                    Y_train, \n",
    "                    10, \n",
    "                    1e-3 , \n",
    "                    'RNN', \n",
    "                    hidden_num=30, \n",
    "                    epoch=20, \n",
    "                    batchSize=100,\n",
    "                    checkPoint=10, \n",
    "                    use_cuda=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(2, 30, batch_first=True)\n",
      "data loader num: 45\n",
      "batch: 10 , loss is:24.993407\n",
      "batch: 20 , loss is:9.579905\n",
      "batch: 30 , loss is:3.737527\n",
      "batch: 40 , loss is:2.676753\n",
      "1 epoch is finished!\n",
      "batch: 10 , loss is:2.442253\n",
      "batch: 20 , loss is:1.473218\n",
      "batch: 30 , loss is:1.281362\n",
      "batch: 40 , loss is:1.071958\n",
      "2 epoch is finished!\n",
      "batch: 10 , loss is:1.022177\n",
      "batch: 20 , loss is:0.397339\n",
      "batch: 30 , loss is:0.249996\n",
      "batch: 40 , loss is:0.179157\n",
      "3 epoch is finished!\n",
      "batch: 10 , loss is:0.162362\n",
      "batch: 20 , loss is:0.083609\n",
      "batch: 30 , loss is:0.099135\n",
      "batch: 40 , loss is:0.069578\n",
      "4 epoch is finished!\n",
      "batch: 10 , loss is:0.101196\n",
      "batch: 20 , loss is:0.059782\n",
      "batch: 30 , loss is:0.059474\n",
      "batch: 40 , loss is:0.055749\n",
      "5 epoch is finished!\n",
      "batch: 10 , loss is:0.058919\n",
      "batch: 20 , loss is:0.048427\n",
      "batch: 30 , loss is:0.046805\n",
      "batch: 40 , loss is:0.048924\n",
      "6 epoch is finished!\n",
      "batch: 10 , loss is:0.058464\n",
      "batch: 20 , loss is:0.029346\n",
      "batch: 30 , loss is:0.032093\n",
      "batch: 40 , loss is:0.036970\n",
      "7 epoch is finished!\n",
      "batch: 10 , loss is:0.046780\n",
      "batch: 20 , loss is:0.025872\n",
      "batch: 30 , loss is:0.034723\n",
      "batch: 40 , loss is:0.030228\n",
      "8 epoch is finished!\n",
      "batch: 10 , loss is:0.040942\n",
      "batch: 20 , loss is:0.029958\n",
      "batch: 30 , loss is:0.023179\n",
      "batch: 40 , loss is:0.022896\n",
      "9 epoch is finished!\n",
      "batch: 10 , loss is:0.040149\n",
      "batch: 20 , loss is:0.019022\n",
      "batch: 30 , loss is:0.022661\n",
      "batch: 40 , loss is:0.022088\n",
      "10 epoch is finished!\n",
      "train time: 6.317784070968628\n"
     ]
    }
   ],
   "source": [
    "trained_LSTM = train(X_train, \n",
    "                     Y_train, \n",
    "                     10, \n",
    "                     1e-3 , \n",
    "                     'LSTM', \n",
    "                     hidden_num=30, \n",
    "                     epoch=10, batchSize=100,checkPoint=10, use_cuda=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = data_targets.loc[:4500,'ID'].unique()\n",
    "data_test_clean = data_clean[data_clean.pedestrian_ID.isin(id_test)]\\\n",
    "    .sort_values(['frame_number']).groupby('pedestrian_ID').head(15)\n",
    "test_obs = len(data_test_clean)//15\n",
    "X_test = data_test_clean[['pos_x','pos_y']].values.reshape(test_obs,15,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_clean = data_clean[data_clean.pedestrian_ID.isin(id_test)]\\\n",
    "    .sort_values(['frame_number']).groupby('pedestrian_ID').head(10)\n",
    "test_obs = len(data_test_clean)//10\n",
    "X_pred = data_test_clean[['pos_x','pos_y']].values.reshape(test_obs,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = data_targets.loc[:4500,'ID'].unique()\n",
    "data_test_clean = data_clean[data_clean.pedestrian_ID.isin(id_test)]\\\n",
    "    .sort_values(['frame_number']).groupby('pedestrian_ID').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_clean['seq'] = data_test_clean.groupby(['pedestrian_ID']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = data_test_clean.pivot(index='pedestrian_ID', columns='seq', values='pos_x').reset_index()\n",
    "y_test = data_test_clean.pivot(index='pedestrian_ID', columns='seq', values='pos_y').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-471-a813f2a6675b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = 10\n",
    "trained_LSTM.eval()\n",
    "X_pred = torch.FloatTensor(X_pred)\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(X_pred[:,-tw:,:])\n",
    "    with torch.no_grad():\n",
    "            #model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "            #                torch.zeros(1, 1, model.hidden_layer_size\n",
    "        pred = trained_LSTM(seq)\n",
    "    X_pred = torch.cat([X_pred, pred.reshape(270,1,2)], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 计算RMSE\n",
    "def calcRMSE(true,pred):\n",
    "    return np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "\n",
    "# 计算MAE\n",
    "def calcMAE(true,pred):\n",
    "    return mean_absolute_error(true, pred)\n",
    "\n",
    "\n",
    "# 计算MAPE\n",
    "def calcMAPE(true, pred, epsion = 0.0000000):\n",
    "\n",
    "    true += epsion\n",
    "    return np.mean(np.abs((true-pred)/true))*100\n",
    "\n",
    "\n",
    "# 计算SMAPE\n",
    "def calcSMAPE(true, pred):\n",
    "    delim = (np.abs(true)+np.abs(pred))/2.0\n",
    "    return np.mean(np.abs((true-pred)/delim))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3437374\n",
      "0.3446669\n"
     ]
    }
   ],
   "source": [
    "print(calcRMSE(Y_train, trainy_pred))\n",
    "print(calcRMSE(Y_test, testy_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26651198\n",
      "0.3147586\n"
     ]
    }
   ],
   "source": [
    "print(calcRMSE(Y_train, trainy_pred_lstm))\n",
    "print(calcRMSE(Y_test, testy_pred_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
